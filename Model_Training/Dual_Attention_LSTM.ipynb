{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59874720",
   "metadata": {},
   "source": [
    "# 병합된 데이터로 Dual_Attention_LSTM 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c371a9b-284e-470a-ae64-136528395329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "seed_value = 743\n",
    "print(\"Train with random seed\", seed_value)\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3957d7b7-58fa-482a-a5e7-05ce40705ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import joblib \n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8de43-a0a5-4d74-a409-776174da0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Lambda, RepeatVector\n",
    "from tensorflow.keras.layers import Input, multiply\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Flatten, Permute, Concatenate\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba801e",
   "metadata": {},
   "source": [
    "## 모델에 입력할 형태로 데이터 변환(window_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f6cfb-c051-497d-b194-7890d4bce77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(name,time_steps):\n",
    "    data=pd.read_csv(\"../Merged_Data/{:s}.csv\".format(name))\n",
    "    \n",
    "    if name.split(\"x\")[-1]=='(Seasonal_Trend)':\n",
    "        \n",
    "        data=data.drop(\"time\",axis=1)\n",
    "        sequences=[]\n",
    "        for i in range(len(data) - time_steps + 1):\n",
    "            sequence = data[i:i+time_steps]\n",
    "            sequences.append(sequence)\n",
    "        return np.array(sequences)\n",
    "    \n",
    "    return np.array(data[23:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263744f-91ef-4900-8919-06b8aa98bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=data_transform('train_x(Seasonal_Trend)',24)\n",
    "train_y=data_transform('train_y',24)\n",
    "test_x=data_transform('test_x(Seasonal_Trend)',24)\n",
    "test_y=data_transform('test_y',24)\n",
    "valid_x=data_transform('valid_x(Seasonal_Trend)',24)\n",
    "valid_y=data_transform('valid_y',24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44072b-64e7-44d9-ab21-1c27d2d6459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d79527",
   "metadata": {},
   "source": [
    "## Dual_Attention_LSTM 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfdbf21-7a03-467c-b2b3-75cd51c3c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_attention_block(inputs, input_dim, single_attention_vector):\n",
    "    time_steps = int(inputs.shape[1])  # 4\n",
    "    a = Dense(input_dim, activation='softmax', name='feature_attention_vec')(\n",
    "        inputs)  # (batch_size, input_dim, time_step)\n",
    "    if single_attention_vector:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='feature_dim_reduction')(a)  # (batch_size, input_dim)\n",
    "        a = RepeatVector(time_steps)(a)  # (batch_size, input_dim, time_step)\n",
    "    output_attention_mul = multiply([inputs, a], name='feature_attention_mul')\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6fa17-4f3c-430d-9118-e2200dc059ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_attention_block(inputs, input_dim, single_attention_vector):\n",
    "    feature_num = int(inputs.shape[2])  # 4\n",
    "    time_steps = int(inputs.shape[1])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Dense(time_steps, activation='softmax', name='time_attention_vec')(a)  # (batch_size, input_dim, time_step)\n",
    "    if single_attention_vector:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='time_dim_reduction')(a)  # (batch_size, input_dim)\n",
    "        a = RepeatVector(feature_num)(a)  # (batch_size, input_dim, time_step)\n",
    "    a = Permute((2, 1))(a)\n",
    "    output_attention_mul = multiply([inputs, a], name='time_attention_mul')\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfea180-52af-4387-b529-a4ce23c2a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_attention_applied_before_lstm(time_step, feature_num, batch_size, input_dim, single_attention_vector):\n",
    "    # inputs = Input(batch_shape=(batch_size, time_step, feature_num))\n",
    "    inputs = Input(shape=(time_step, feature_num))\n",
    "    time_x = time_attention_block(inputs, input_dim, single_attention_vector)\n",
    "    feature_x = feature_attention_block(inputs, input_dim, single_attention_vector)\n",
    "    x = Concatenate(axis=2)([time_x, feature_x])\n",
    "    x = LSTM(6, activation='tanh',\n",
    "             stateful=False,\n",
    "             return_sequences=True,\n",
    "             kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(10, activation='linear', kernel_regularizer=regularizers.l2(0.01),\n",
    "              activity_regularizer=regularizers.l1(0.))(x)\n",
    "    output = Dense(1, activation='linear', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    # model = Model(input=[inputs], output=output)\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8311da00",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e7067-c127-4626-8ec5-510531257b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "look_back = 24\n",
    "feature_num = 5\n",
    "SINGLE_ATTENTION_VECTOR = True\n",
    "\n",
    "model = model_attention_applied_before_lstm(look_back, feature_num, batch_size, feature_num, SINGLE_ATTENTION_VECTOR)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107c8ca5",
   "metadata": {},
   "source": [
    "## 모델 훈련(epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ba5bb-9f16-4f8b-860a-94b353720835",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_x, train_y,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    batch_size=batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss를 시각화하여 학습 횟수의 적합성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# train loss와 validation loss의 변화를 matplotlib를 사용해 시각화함\n",
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185b66a7",
   "metadata": {},
   "source": [
    "## 모델 저장, test set 예측 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d8a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./Saved_Model/Dual_Attention_LSTM(epoch=100).pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(train_x, batch_size)\n",
    "valid_predict = model.predict(valid_x, batch_size)\n",
    "test_predict = model.predict(test_x, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39550aea",
   "metadata": {},
   "source": [
    "## sclaer를 불러와서 inverse transform 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d312e-7201-4011-becf-824312f4771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "scaler=joblib.load('../Merged_Data/Scaler/Y_pm10.pkl')\n",
    "\n",
    "inv_train_y = scaler.inverse_transform(train_y)\n",
    "inv_train_predict = scaler.inverse_transform(train_predict)\n",
    "inv_valid_y = scaler.inverse_transform(valid_y)\n",
    "inv_valid_predict = scaler.inverse_transform(valid_predict)\n",
    "inv_test_y = scaler.inverse_transform(test_y)\n",
    "inv_test_predict = scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8c276",
   "metadata": {},
   "source": [
    "## 성능 평가 : SMAPE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90a36c-e296-4c17-91db-9af2085ef75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Symmetric_mean_absolute_percentage_error(actual, predicted):\n",
    "    \n",
    "    total=len(actual)\n",
    "    numerator=np.abs(actual-predicted)\n",
    "    denominator=np.abs(actual)+np.abs(predicted)\n",
    "    SMAPE=(100/total)*np.sum(numerator/denominator)\n",
    "    \n",
    "    return SMAPE\n",
    "\n",
    "from sklearn.metrics import mean_squared_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smape = Symmetric_mean_absolute_percentage_error(inv_train_y, inv_train_predict)\n",
    "valid_smape = Symmetric_mean_absolute_percentage_error(inv_valid_y, inv_valid_predict)\n",
    "test_smape = Symmetric_mean_absolute_percentage_error(inv_test_y, inv_test_predict)\n",
    "\n",
    "train_rmse = mean_squared_error (inv_train_y, inv_train_predict)\n",
    "train_rmse=np.sqrt(train_rmse)\n",
    "valid_rmse = mean_squared_error (inv_valid_y, inv_valid_predict)\n",
    "valid_rmse=np.sqrt(valid_rmse)\n",
    "test_rmse = mean_squared_error (inv_test_y, inv_test_predict)\n",
    "test_rmse=np.sqrt(test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7308a-2161-44fa-8f40-0b2a269728c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train SMAPE:\", train_smape)\n",
    "print(\"Valid SMAPE:\", test_smape)\n",
    "print(\"Test SMAPE:\", valid_smape)\n",
    "\n",
    "print(\"Train RMSE:\", train_rmse)\n",
    "print(\"Valid RMSE:\", test_rmse)\n",
    "print(\"Test RMSE:\", valid_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b10c8b",
   "metadata": {},
   "source": [
    "## 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9c528-0d63-4bf0-8745-46521f9596d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualization_self(train_term,name,test_y,pred_y):\n",
    "    plt.figure(figsize=(32, 16))\n",
    "    \n",
    "    plt.plot(np.arange(train_term), test_y[:train_term], color='red', ls='-', lw=3, label='Raw Data')\n",
    "    plt.plot(np.arange(train_term), pred_y[:train_term], color='blue', ls='--', lw=3, label='Raw Data')\n",
    "    \n",
    "    plt.xlabel('[Time]', fontsize=25, fontweight='bold')\n",
    "    plt.ylabel('[PM10]', fontsize=25, fontweight='bold')\n",
    "    plt.title('Prediction Visualization({:s})'.format(name),fontsize=30, weight='bold')\n",
    "    plt.xticks( fontsize=15, fontweight='bold')\n",
    "    plt.yticks( fontsize=15, fontweight='bold')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualization_self(len(inv_test_y),'Dual_Attention_LSTM,epoch=100',inv_test_y,inv_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c656ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualization_self(200,'Dual_Attention_LSTM,epoch=100',inv_test_y,inv_test_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
