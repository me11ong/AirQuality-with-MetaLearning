{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47138eb",
   "metadata": {},
   "source": [
    "# 병합된 데이터로 Attention_LSTM 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c371a9b-284e-470a-ae64-136528395329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "seed_value = 743\n",
    "print(\"Train with random seed\", seed_value)\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3957d7b7-58fa-482a-a5e7-05ce40705ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import joblib \n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Lambda, RepeatVector\n",
    "from tensorflow.keras.layers import Input, multiply\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Flatten\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f509fb7d",
   "metadata": {},
   "source": [
    "## 훈련할 데이터 load, 입력에 맞게 변환(window_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779ef9a-e29b-4902-944b-e699a58f126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(name,time_steps):\n",
    "    data=pd.read_csv(\"../Merged_Data/{:s}.csv\".format(name))\n",
    "    \n",
    "    if name.split(\"x\")[-1]=='(Seasonal_Trend)':\n",
    "        \n",
    "        data=data.drop(\"time\",axis=1)\n",
    "        sequences=[]\n",
    "        for i in range(len(data) - time_steps + 1):\n",
    "            sequence = data[i:i+time_steps]\n",
    "            sequences.append(sequence)\n",
    "        return np.array(sequences)\n",
    "    \n",
    "    return np.array(data[23:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f6cfb-c051-497d-b194-7890d4bce77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=data_transform('train_x(Seasonal_Trend)',24)\n",
    "train_y=data_transform('train_y',24)\n",
    "test_x=data_transform('test_x(Seasonal_Trend)',24)\n",
    "test_y=data_transform('test_y',24)\n",
    "valid_x=data_transform('valid_x(Seasonal_Trend)',24)\n",
    "valid_y=data_transform('valid_y',24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44072b-64e7-44d9-ab21-1c27d2d6459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf335a1d",
   "metadata": {},
   "source": [
    "## Attention_LSTM 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0a00e-a597-471c-a27b-0612868913eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs, input_dim, single_attention_vector):\n",
    "    \"\"\"Feature attention block 정의\"\"\"\n",
    "    time_steps = int(inputs.shape[1])\n",
    "    # Attention weights 계산\n",
    "    a = Dense(input_dim, activation='softmax', name='attention_vec')(inputs)  # (batch_size, input_dim, time_step)\n",
    "    if single_attention_vector:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)  # (batch_size, input_dim)\n",
    "        a = RepeatVector(time_steps)(a)  # (batch_size, input_dim, time_step)\n",
    "    output_attention_mul = multiply([inputs, a], name='attention_mul')  # Attention weights 적용\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63331400-8b0e-48b1-a266-59a154d9c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_attention_applied_before_lstm(batch_size, time_step, feature_num, single_attention_vector):\n",
    "    \"\"\"Attention LSTM 모델 정의\"\"\"\n",
    "    inputs = Input(shape=(time_step, feature_num))\n",
    "    x = attention_3d_block(inputs, feature_num, single_attention_vector)\n",
    "    x = LSTM(6, activation='tanh',\n",
    "            stateful=False,\n",
    "            return_sequences=True,\n",
    "            kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(10, activation='linear', kernel_regularizer=regularizers.l2(0.01),\n",
    "              activity_regularizer=regularizers.l1(0.))(x)\n",
    "    output = Dense(1, activation='linear', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59954698",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e7067-c127-4626-8ec5-510531257b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "look_back = 24\n",
    "feature_num = 5\n",
    "SINGLE_ATTENTION_VECTOR = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_attention_applied_before_lstm(batch_size, look_back, feature_num, SINGLE_ATTENTION_VECTOR)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6759177b",
   "metadata": {},
   "source": [
    "## 모델 훈련(epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ba5bb-9f16-4f8b-860a-94b353720835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 진행\n",
    "# 훈련 과정의 손실값을 history 변수에 저장\n",
    "history = model.fit(train_x, train_y,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    batch_size=batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss를 시각화하여 학습 횟수의 적합성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# train loss와 validation loss의 변화를 matplotlib를 사용해 시각화함\n",
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca35e6",
   "metadata": {},
   "source": [
    "## 모델 저장, 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ab8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./Saved_Model/Attention_LSTM(epoch=100).pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(train_x, batch_size)\n",
    "valid_predict = model.predict(valid_x, batch_size)\n",
    "test_predict = model.predict(test_x, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed830a59",
   "metadata": {},
   "source": [
    "## sclaer를 불러와서 inverse transform 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc1b7d-2866-4d59-ba50-e289a4fae185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "scaler=joblib.load('../Merged_Data/Scaler/Y_pm10.pkl')\n",
    "\n",
    "inv_train_y = scaler.inverse_transform(train_y)\n",
    "inv_train_predict = scaler.inverse_transform(train_predict)\n",
    "inv_valid_y = scaler.inverse_transform(valid_y)\n",
    "inv_valid_predict = scaler.inverse_transform(valid_predict)\n",
    "inv_test_y = scaler.inverse_transform(test_y)\n",
    "inv_test_predict = scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c77643",
   "metadata": {},
   "source": [
    "## 성능 평가 : SMAPE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7308a-2161-44fa-8f40-0b2a269728c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Symmetric_mean_absolute_percentage_error(actual, predicted):\n",
    "    \n",
    "    total=len(actual)\n",
    "    numerator=np.abs(actual-predicted)\n",
    "    denominator=np.abs(actual)+np.abs(predicted)\n",
    "    SMAPE=(100/total)*np.sum(numerator/denominator)\n",
    "    \n",
    "    return SMAPE\n",
    "\n",
    "from sklearn.metrics import mean_squared_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smape = Symmetric_mean_absolute_percentage_error(inv_train_y, inv_train_predict)\n",
    "valid_smape = Symmetric_mean_absolute_percentage_error(inv_valid_y, inv_valid_predict)\n",
    "test_smape = Symmetric_mean_absolute_percentage_error(inv_test_y, inv_test_predict)\n",
    "\n",
    "train_rmse = mean_squared_error (inv_train_y, inv_train_predict)\n",
    "train_rmse=np.sqrt(train_rmse)\n",
    "valid_rmse = mean_squared_error (inv_valid_y, inv_valid_predict)\n",
    "valid_rmse=np.sqrt(valid_rmse)\n",
    "test_rmse = mean_squared_error (inv_test_y, inv_test_predict)\n",
    "test_rmse=np.sqrt(test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train SMAPE:\", train_smape)\n",
    "print(\"Valid SMAPE:\", test_smape)\n",
    "print(\"Test SMAPE:\", valid_smape)\n",
    "\n",
    "print(\"Train RMSE:\", train_rmse)\n",
    "print(\"Valid RMSE:\", test_rmse)\n",
    "print(\"Test RMSE:\", valid_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf58f03",
   "metadata": {},
   "source": [
    "## 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64267581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualization_self(train_term,name,test_y,pred_y):\n",
    "    plt.figure(figsize=(32, 16))\n",
    "    \n",
    "    plt.plot(np.arange(train_term), test_y[:train_term], color='red', ls='-', lw=3, label='Raw Data')\n",
    "    plt.plot(np.arange(train_term), pred_y[:train_term], color='blue', ls='--', lw=3, label='Raw Data')\n",
    "    \n",
    "    plt.xlabel('[Time]', fontsize=25, fontweight='bold')\n",
    "    plt.ylabel('[PM10]', fontsize=25, fontweight='bold')\n",
    "    plt.title('Prediction Visualization({:s})'.format(name),fontsize=30, weight='bold')\n",
    "    plt.xticks( fontsize=15, fontweight='bold')\n",
    "    plt.yticks( fontsize=15, fontweight='bold')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df02e87-cae8-464a-afc7-cb29a89230bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualization_self(len(inv_test_y),'Attention-LSTM,epoch=100',inv_test_y,inv_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualization_self(200,'Attention-LSTM,epoch=100',inv_test_y,inv_test_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
