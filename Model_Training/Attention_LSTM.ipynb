{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47138eb",
   "metadata": {},
   "source": [
    "# 병합된 데이터로 Attention_LSTM 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c371a9b-284e-470a-ae64-136528395329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with random seed 743\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "seed_value = 743\n",
    "print(\"Train with random seed\", seed_value)\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3957d7b7-58fa-482a-a5e7-05ce40705ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import joblib \n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Lambda, RepeatVector\n",
    "from tensorflow.keras.layers import Input, multiply\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Flatten\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1a6a21",
   "metadata": {},
   "source": [
    "## 평가 지표 : SMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b7a954-6d02-470e-a03c-b6fcd8c7c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to return the SMAPE value\n",
    "def calculate_smape(actual, predicted) -> float:\n",
    "    \"\"\"SMAPE 성능 지표를 계산하기 위한 함수 정의\"\"\"\n",
    "  \n",
    "    # Convert actual and predicted to numpy\n",
    "    # array data type if not already\n",
    "    if not all([isinstance(actual, np.ndarray), \n",
    "                isinstance(predicted, np.ndarray)]):\n",
    "        actual, predicted = np.array(actual),\n",
    "        np.array(predicted)\n",
    "  \n",
    "    return round(\n",
    "        np.mean(\n",
    "            np.abs(predicted - actual) / \n",
    "            ((np.abs(predicted) + np.abs(actual))/2)\n",
    "        )*100, 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f509fb7d",
   "metadata": {},
   "source": [
    "## 훈련할 데이터 load, 입력에 맞게 변환(window_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ba1a74-e699-4ad1-a77c-9258ca473275",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../Merged_Data(droped)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8779ef9a-e29b-4902-944b-e699a58f126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_df = pd.read_csv(os.path.join(data_path, 'train_x.csv'))\n",
    "train_y_df = pd.read_csv(os.path.join(data_path, 'train_y.csv'))\n",
    "test_x_df = pd.read_csv(os.path.join(data_path, 'test_x.csv'))\n",
    "test_y_df = pd.read_csv(os.path.join(data_path, 'test_y.csv'))\n",
    "valid_x_df = pd.read_csv(os.path.join(data_path, 'valid_x.csv'))\n",
    "valid_y_df = pd.read_csv(os.path.join(data_path, 'valid_y.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b3f6cfb-c051-497d-b194-7890d4bce77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, window_size=24):\n",
    "    data_x, data_y = [], []\n",
    "    assert len(X) == len(y)\n",
    "    for i in range(len(X) - window_size + 1):\n",
    "        input_data = X[i: i + window_size, :]\n",
    "        target_data = y[i + window_size - 1, 0]\n",
    "        data_x.append(input_data)\n",
    "        data_y.append(target_data)\n",
    "\n",
    "    return np.array(data_x), np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c263744f-91ef-4900-8919-06b8aa98bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = create_dataset(train_x_df.values, train_y_df.values)\n",
    "test_X, test_y = create_dataset(test_x_df.values, test_y_df.values)\n",
    "valid_X, valid_y = create_dataset(valid_x_df.values, valid_y_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da44072b-64e7-44d9-ab21-1c27d2d6459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55204, 24, 5) (55204,)\n",
      "(3045, 24, 5) (3045,)\n",
      "(3046, 24, 5) (3046,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape)\n",
    "print(valid_X.shape, valid_y.shape)\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf335a1d",
   "metadata": {},
   "source": [
    "## Attention_LSTM 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b0a00e-a597-471c-a27b-0612868913eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs, input_dim, single_attention_vector):\n",
    "    \"\"\"Feature attention block 정의\"\"\"\n",
    "    time_steps = int(inputs.shape[1])\n",
    "    # Attention weights 계산\n",
    "    a = Dense(input_dim, activation='softmax', name='attention_vec')(inputs)  # (batch_size, input_dim, time_step)\n",
    "    if single_attention_vector:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)  # (batch_size, input_dim)\n",
    "        a = RepeatVector(time_steps)(a)  # (batch_size, input_dim, time_step)\n",
    "    output_attention_mul = multiply([inputs, a], name='attention_mul')  # Attention weights 적용\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63331400-8b0e-48b1-a266-59a154d9c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_attention_applied_before_lstm(batch_size, time_step, feature_num, single_attention_vector):\n",
    "    \"\"\"Attention LSTM 모델 정의\"\"\"\n",
    "    inputs = Input(shape=(time_step, feature_num))\n",
    "    x = attention_3d_block(inputs, feature_num, single_attention_vector)\n",
    "    x = LSTM(6, activation='tanh',\n",
    "             stateful=False,\n",
    "             return_sequences=True,\n",
    "             kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(10, activation='linear', kernel_regularizer=regularizers.l2(0.01),\n",
    "              activity_regularizer=regularizers.l1(0.))(x)\n",
    "    output = Dense(1, activation='linear', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59954698",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a98e7067-c127-4626-8ec5-510531257b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "look_back = 24\n",
    "feature_num = 5\n",
    "SINGLE_ATTENTION_VECTOR = True\n",
    "\n",
    "model = model_attention_applied_before_lstm(batch_size, look_back, feature_num, SINGLE_ATTENTION_VECTOR)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6759177b",
   "metadata": {},
   "source": [
    "## 모델 훈련(epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "570ba5bb-9f16-4f8b-860a-94b353720835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13801/13801 [==============================] - 45s 3ms/step - loss: 0.0175 - val_loss: 0.0066\n",
      "Epoch 2/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 4/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 5/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 6/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 7/100\n",
      "13801/13801 [==============================] - 46s 3ms/step - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 8/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 9/100\n",
      "13801/13801 [==============================] - 42s 3ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 10/100\n",
      "13801/13801 [==============================] - 42s 3ms/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 11/100\n",
      "13801/13801 [==============================] - 41s 3ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 12/100\n",
      "13801/13801 [==============================] - 40s 3ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 13/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 14/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 15/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 16/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 17/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 18/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 19/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 20/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 21/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 22/100\n",
      "13801/13801 [==============================] - 45s 3ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 23/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 24/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 25/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 26/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 27/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 28/100\n",
      "13801/13801 [==============================] - 45s 3ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 29/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 30/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 31/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 32/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 33/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 34/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 35/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 36/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 37/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 38/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 39/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 40/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 41/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 42/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 43/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 44/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 45/100\n",
      "13801/13801 [==============================] - 44s 3ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 46/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 47/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 48/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 49/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 50/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 51/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 52/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 53/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 54/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 55/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 56/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 57/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 58/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 59/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 60/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 61/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 62/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 63/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 64/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 65/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 66/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 67/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 68/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 69/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 70/100\n",
      "13801/13801 [==============================] - 42s 3ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 71/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 72/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 73/100\n",
      "13801/13801 [==============================] - 42s 3ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 74/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 75/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 76/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 77/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 78/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 79/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 80/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 81/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 82/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 83/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 84/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 85/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 86/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 87/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 88/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 89/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 90/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 91/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 92/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 93/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 94/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 95/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 96/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 97/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 98/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 99/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 100/100\n",
      "13801/13801 [==============================] - 43s 3ms/step - loss: 0.0060 - val_loss: 0.0048\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련 진행\n",
    "# 훈련 과정의 손실값을 history 변수에 저장\n",
    "history = model.fit(train_X, train_y,\n",
    "                    validation_data=(valid_X, valid_y),\n",
    "                    batch_size=batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca35e6",
   "metadata": {},
   "source": [
    "## 모델 저장, test set 예측 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "513ab8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Saved_Model/Attention_LSTM(epoch=100).pt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Saved_Model/Attention_LSTM(epoch=100).pt\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000013C6E111A20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save('./Saved_Model/Attention_LSTM(epoch=100).pt')\n",
    "test_predict = model.predict(test_X, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed830a59",
   "metadata": {},
   "source": [
    "## sclaer를 불러와서 inverse transform 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07cc1b7d-2866-4d59-ba50-e289a4fae185",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load('../Merged_Data/Scaler/Y_pm10.pkl')\n",
    "inv_test_y = scaler.inverse_transform(test_y.reshape(-1, 1))\n",
    "inv_test_predict = scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c77643",
   "metadata": {},
   "source": [
    "## 성능 평가 : SMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aef7308a-2161-44fa-8f40-0b2a269728c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train SMAPE: 22.31\n",
      "Valid SMAPE: 30.70\n",
      "Test SMAPE: 16.02\n"
     ]
    }
   ],
   "source": [
    "test_smape = calculate_smape(inv_test_y, inv_test_predict)\n",
    "print(\"Test SMAPE: %.2f\" % test_smape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf58f03",
   "metadata": {},
   "source": [
    "## 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64267581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualization_self(train_term,name,test_y,pred_y):\n",
    "    plt.figure(figsize=(32, 16))\n",
    "    \n",
    "    plt.plot(np.arange(train_term), test_y[:train_term], color='red', ls='-', lw=3, label='Raw Data')\n",
    "    plt.plot(np.arange(train_term), pred_y[:train_term], color='blue', ls='--', lw=3, label='Raw Data')\n",
    "    \n",
    "    plt.xlabel('[Time]', fontsize=25, fontweight='bold')\n",
    "    plt.ylabel('[PM10]', fontsize=25, fontweight='bold')\n",
    "    plt.title('Prediction Visualization({:s})'.format(name),fontsize=30, weight='bold')\n",
    "    plt.xticks( fontsize=15, fontweight='bold')\n",
    "    plt.yticks( fontsize=15, fontweight='bold')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df02e87-cae8-464a-afc7-cb29a89230bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualization_self(len(inv_test_y),'CNN-LSTM,epoch=100',inv_test_y,inv_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualization_self(200,'CNN-LSTM,epoch=100',inv_test_y,inv_test_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
