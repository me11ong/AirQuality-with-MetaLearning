{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STL을 적용한 데이터로 LSTM 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.font_manager as font_manager\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 구축하기 위한 keras 관련 함수\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Lambda, RepeatVector\n",
    "from tensorflow.keras.layers import Input, multiply\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Flatten\n",
    "from tensorflow.keras import regularizers\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM모델에 입력할 형태로 데이터 변환(window_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(name,time_steps):\n",
    "    data=pd.read_csv(\"../Merged_Data/{:s}.csv\".format(name))\n",
    "    \n",
    "    if name.split(\"x\")[-1]=='(Seasonal_Trend)':\n",
    "        \n",
    "        data=data.drop(\"time\",axis=1)\n",
    "        sequences=[]\n",
    "        for i in range(len(data) - time_steps + 1):\n",
    "            sequence = data[i:i+time_steps]\n",
    "            sequences.append(sequence)\n",
    "        return np.array(sequences)\n",
    "    \n",
    "    return np.array(data[23:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=data_transform('train_x(Seasonal_Trend)',24)\n",
    "train_y=data_transform('train_y',24)\n",
    "test_x=data_transform('test_x(Seasonal_Trend)',24)\n",
    "test_y=data_transform('test_y',24)\n",
    "valid_x=data_transform('valid_x(Seasonal_Trend)',24)\n",
    "valid_y=data_transform('valid_y',24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(batch_size, time_step, feature_num):\n",
    "        \"\"\"LSTM 모델 정의\"\"\"\n",
    "        inputs = Input(shape=(time_step, feature_num))\n",
    "        x = LSTM(6, activation='tanh',\n",
    "        stateful=False,\n",
    "        return_sequences=True,\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(10, activation='linear', kernel_regularizer=regularizers.l2(0.01),\n",
    "        activity_regularizer=regularizers.l1(0.))(x)\n",
    "        output = Dense(1, activation='linear', kernel_initializer='he_normal')(x)\n",
    "\n",
    "        model = Model(inputs=[inputs], outputs=output)\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "        return model,early_stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "time_steps = 24\n",
    "feature_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,early_stopping=lstm_model(batch_size, time_steps, feature_num)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련(epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_x, train_y,\n",
    "                    validation_data=(valid_x, valid_y),\n",
    "                    batch_size=batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss를 시각화하여 학습 횟수의 적합성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# train loss와 validation loss의 변화를 matplotlib를 사용해 시각화함\n",
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장, 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./Saved_Model/LSTM(epoch=100).pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(train_x, batch_size)\n",
    "valid_predict = model.predict(valid_x, batch_size)\n",
    "test_predict = model.predict(test_x, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sclaer를 불러와서 inverse transform 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "scaler=joblib.load('../Merged_Data/Scaler/Y_pm10.pkl')\n",
    "\n",
    "inv_train_y = scaler.inverse_transform(train_y)\n",
    "inv_train_predict = scaler.inverse_transform(train_predict)\n",
    "inv_valid_y = scaler.inverse_transform(valid_y)\n",
    "inv_valid_predict = scaler.inverse_transform(valid_predict)\n",
    "inv_test_y = scaler.inverse_transform(test_y)\n",
    "inv_test_predict = scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 평가 : SMAPE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Symmetric_mean_absolute_percentage_error(actual, predicted):\n",
    "    \n",
    "    total=len(actual)\n",
    "    numerator=np.abs(actual-predicted)\n",
    "    denominator=np.abs(actual)+np.abs(predicted)\n",
    "    SMAPE=(100/total)*np.sum(numerator/denominator)\n",
    "    \n",
    "    return SMAPE\n",
    "\n",
    "from sklearn.metrics import mean_squared_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smape = Symmetric_mean_absolute_percentage_error(inv_train_y, inv_train_predict)\n",
    "valid_smape = Symmetric_mean_absolute_percentage_error(inv_valid_y, inv_valid_predict)\n",
    "test_smape = Symmetric_mean_absolute_percentage_error(inv_test_y, inv_test_predict)\n",
    "\n",
    "train_rmse = mean_squared_error (inv_train_y, inv_train_predict)\n",
    "train_rmse=np.sqrt(train_rmse)\n",
    "valid_rmse = mean_squared_error (inv_valid_y, inv_valid_predict)\n",
    "valid_rmse=np.sqrt(valid_rmse)\n",
    "test_rmse = mean_squared_error (inv_test_y, inv_test_predict)\n",
    "test_rmse=np.sqrt(test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train SMAPE:\", train_smape)\n",
    "print(\"Valid SMAPE:\", test_smape)\n",
    "print(\"Test SMAPE:\", valid_smape)\n",
    "\n",
    "print(\"Train RMSE:\", train_rmse)\n",
    "print(\"Valid RMSE:\", test_rmse)\n",
    "print(\"Test RMSE:\", valid_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualization_self(train_term,name,test_y,pred_y):\n",
    "    plt.figure(figsize=(32, 16))\n",
    "    \n",
    "    plt.plot(np.arange(train_term), test_y[:train_term], color='red', ls='-', lw=3, label='Raw Data')\n",
    "    plt.plot(np.arange(train_term), pred_y[:train_term], color='blue', ls='--', lw=3, label='Raw Data')\n",
    "    \n",
    "    plt.xlabel('[Time]', fontsize=25, fontweight='bold')\n",
    "    plt.ylabel('[PM10]', fontsize=25, fontweight='bold')\n",
    "    plt.title('Prediction Visualization({:s})'.format(name),fontsize=30, weight='bold')\n",
    "    plt.xticks( fontsize=15, fontweight='bold')\n",
    "    plt.yticks( fontsize=15, fontweight='bold')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualization_self(len(inv_test_y),'LSTM, epoch=100',inv_test_y,inv_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualization_self(200,'LSTM, epoch=100',inv_test_y,inv_test_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d_linear",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
